{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0IpEG0n1w8zp"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.utils import save_image\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import os\n",
    "import glob\n",
    "import PIL\n",
    "from PIL import Image\n",
    "from torch.utils import data as D\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "import random\n",
    "import torchsummary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1909,
     "status": "ok",
     "timestamp": 1549779074258,
     "user": {
      "displayName": "PUBG호야",
      "photoUrl": "https://lh3.googleusercontent.com/-995djavMjjs/AAAAAAAAAAI/AAAAAAAAAGI/vwiBSSQLtiQ/s64/photo.jpg",
      "userId": "15725788610401702262"
     },
     "user_tz": -540
    },
    "id": "quWno9W_xJmD",
    "outputId": "6c8d0c21-5289-4ca5-aeba-5dceb3167236"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0.0\n",
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "print(torch.__version__)\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OLKeDNrgxMJO"
   },
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "validation_ratio = 0.1\n",
    "random_seed = 10\n",
    "initial_lr = 0.1\n",
    "num_epoch = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 29950,
     "status": "ok",
     "timestamp": 1549779102329,
     "user": {
      "displayName": "PUBG호야",
      "photoUrl": "https://lh3.googleusercontent.com/-995djavMjjs/AAAAAAAAAAI/AAAAAAAAAGI/vwiBSSQLtiQ/s64/photo.jpg",
      "userId": "15725788610401702262"
     },
     "user_tz": -540
    },
    "id": "C-dON3NcxM6c",
    "outputId": "f2df4f46-7318-466b-c179-ab484243ba35"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "transform_train = transforms.Compose([\n",
    "        transforms.RandomResizedCrop(224),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2470, 0.2435, 0.2616))])\n",
    "\n",
    "transform_validation = transforms.Compose([\n",
    "        transforms.Resize(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2470, 0.2435, 0.2616))])\n",
    "\n",
    "\n",
    "transform_test = transforms.Compose([\n",
    "        transforms.Resize(224),     \n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2470, 0.2435, 0.2616))])\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(\n",
    "    root='./data', train=True, download=True, transform=transform_train)\n",
    "\n",
    "validset = torchvision.datasets.CIFAR10(\n",
    "    root='./data', train=True, download=True, transform=transform_validation)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(\n",
    "    root='./data', train=False, download=True, transform=transform_test)\n",
    "\n",
    "\n",
    "num_train = len(trainset)\n",
    "indices = list(range(num_train))\n",
    "split = int(np.floor(validation_ratio * num_train))\n",
    "\n",
    "np.random.seed(random_seed)\n",
    "np.random.shuffle(indices)\n",
    "\n",
    "train_idx, valid_idx = indices[split:], indices[:split]\n",
    "train_sampler = SubsetRandomSampler(train_idx)\n",
    "valid_sampler = SubsetRandomSampler(valid_idx)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    trainset, batch_size=batch_size, sampler=train_sampler, num_workers=0\n",
    ")\n",
    "\n",
    "valid_loader = torch.utils.data.DataLoader(\n",
    "    validset, batch_size=batch_size, sampler=valid_sampler, num_workers=0\n",
    ")\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    testset, batch_size=batch_size, shuffle=False, num_workers=0\n",
    ")\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat',\n",
    "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2_Wdkl-TxQBz"
   },
   "outputs": [],
   "source": [
    "class conv_bn_relu(nn.Module):\n",
    "    def __init__(self, nin, nout, kernel_size, stride, padding, bias=False):\n",
    "        super(conv_bn_relu, self).__init__()\n",
    "        self.conv = nn.Conv2d(nin, nout, kernel_size=kernel_size, stride=stride, padding=padding, bias=bias)\n",
    "        self.batch_norm = nn.BatchNorm2d(nout)\n",
    "        self.relu = nn.ReLU(True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.conv(x)\n",
    "        out = self.batch_norm(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2OXj4ClU0t0B"
   },
   "outputs": [],
   "source": [
    "class Transition_layer(nn.Sequential):\n",
    "  def __init__(self, nin, theta=1):    \n",
    "      super(Transition_layer, self).__init__()\n",
    "      \n",
    "      self.add_module('conv_1x1', conv_bn_relu(nin=nin, nout=int(nin*theta), kernel_size=1, stride=1, padding=0, bias=False))\n",
    "      self.add_module('avg_pool_2x2', nn.AvgPool2d(kernel_size=2, stride=2, padding=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IFlC3oaM0V4q"
   },
   "outputs": [],
   "source": [
    "class StemBlock(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(StemBlock, self).__init__()\n",
    "        \n",
    "        self.conv_3x3_first = conv_bn_relu(nin=3, nout=32, kernel_size=3, stride=2, padding=1, bias=False)\n",
    "        \n",
    "        self.conv_1x1_left = conv_bn_relu(nin=32, nout=16, kernel_size=1, stride=1, padding=0, bias=False)\n",
    "        self.conv_3x3_left = conv_bn_relu(nin=16, nout=32, kernel_size=3, stride=2, padding=1, bias=False)\n",
    "        \n",
    "        self.max_pool_right = nn.MaxPool2d(kernel_size=2, stride=2, padding=0)\n",
    "        \n",
    "        self.conv_1x1_last = conv_bn_relu(nin=64, nout=32, kernel_size=1, stride=1, padding=0, bias=False)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out_first = self.conv_3x3_first(x)\n",
    "        \n",
    "        out_left = self.conv_1x1_left(out_first)\n",
    "        out_left = self.conv_3x3_left(out_left)\n",
    "        \n",
    "        out_right = self.max_pool_right(out_first)\n",
    "        \n",
    "        out_middle = torch.cat((out_left, out_right), 1)\n",
    "        \n",
    "        out_last = self.conv_1x1_last(out_middle)\n",
    "                \n",
    "        return out_last"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "aSZQgu02xUKy"
   },
   "outputs": [],
   "source": [
    "class dense_layer(nn.Module):\n",
    "  def __init__(self, nin, growth_rate, drop_rate=0.2):    \n",
    "      super(dense_layer, self).__init__()\n",
    "      \n",
    "      self.dense_left_way = nn.Sequential()\n",
    "      \n",
    "      self.dense_left_way.add_module('conv_1x1', conv_bn_relu(nin=nin, nout=growth_rate*2, kernel_size=1, stride=1, padding=0, bias=False))\n",
    "      self.dense_left_way.add_module('conv_3x3', conv_bn_relu(nin=growth_rate*2, nout=growth_rate//2, kernel_size=3, stride=1, padding=1, bias=False))\n",
    "            \n",
    "      self.dense_right_way = nn.Sequential()\n",
    "      \n",
    "      self.dense_right_way.add_module('conv_1x1', conv_bn_relu(nin=nin, nout=growth_rate*2, kernel_size=1, stride=1, padding=0, bias=False))\n",
    "      self.dense_right_way.add_module('conv_3x3_1', conv_bn_relu(nin=growth_rate*2, nout=growth_rate//2, kernel_size=3, stride=1, padding=1, bias=False))\n",
    "      self.dense_right_way.add_module('conv_3x3 2', conv_bn_relu(nin=growth_rate//2, nout=growth_rate//2, kernel_size=3, stride=1, padding=1, bias=False))\n",
    "      \n",
    "      self.drop_rate = drop_rate\n",
    "      \n",
    "  def forward(self, x):\n",
    "      left_output = self.dense_left_way(x)\n",
    "      right_output = self.dense_right_way(x)\n",
    "\n",
    "      if self.drop_rate > 0:\n",
    "          left_output = F.dropout(left_output, p=self.drop_rate, training=self.training)\n",
    "          right_output = F.dropout(right_output, p=self.drop_rate, training=self.training)\n",
    "          \n",
    "      dense_layer_output = torch.cat((x, left_output, right_output), 1)\n",
    "            \n",
    "      return dense_layer_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zBpPsc18xWiD"
   },
   "outputs": [],
   "source": [
    "class DenseBlock(nn.Sequential):\n",
    "  def __init__(self, nin, num_dense_layers, growth_rate, drop_rate=0.0):\n",
    "      super(DenseBlock, self).__init__()\n",
    "                        \n",
    "      for i in range(num_dense_layers):\n",
    "          nin_dense_layer = nin + growth_rate * i\n",
    "          self.add_module('dense_layer_%d' % i, dense_layer(nin=nin_dense_layer, growth_rate=growth_rate, drop_rate=drop_rate))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mmk5h_QXxYoh"
   },
   "outputs": [],
   "source": [
    "class PeleeNet(nn.Module):\n",
    "    def __init__(self, growth_rate=32, num_dense_layers=[3,4,8,6], theta=1, drop_rate=0.0, num_classes=10):\n",
    "        super(PeleeNet, self).__init__()\n",
    "        \n",
    "        assert len(num_dense_layers) == 4\n",
    "        \n",
    "        self.features = nn.Sequential()\n",
    "        self.features.add_module('StemBlock', StemBlock())\n",
    "        \n",
    "        nin_transition_layer = 32\n",
    "        \n",
    "        for i in range(len(num_dense_layers)):\n",
    "            self.features.add_module('DenseBlock_%d' % (i+1), DenseBlock(nin=nin_transition_layer, num_dense_layers=num_dense_layers[i], growth_rate=growth_rate, drop_rate=0.0))\n",
    "            nin_transition_layer +=  num_dense_layers[i] * growth_rate\n",
    "            \n",
    "            if i == len(num_dense_layers) - 1:\n",
    "                self.features.add_module('Transition_layer_%d' % (i+1), conv_bn_relu(nin=nin_transition_layer, nout=int(nin_transition_layer*theta), kernel_size=1, stride=1, padding=0, bias=False))\n",
    "            else:\n",
    "                self.features.add_module('Transition_layer_%d' % (i+1), Transition_layer(nin=nin_transition_layer, theta=1))\n",
    "        \n",
    "        self.linear = nn.Linear(nin_transition_layer, num_classes)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        stage_output = self.features(x)\n",
    "        \n",
    "        global_avg_pool_output = F.adaptive_avg_pool2d(stage_output, (1, 1))  \n",
    "        global_avg_pool_output_flat = global_avg_pool_output.view(global_avg_pool_output.size(0), -1)\n",
    "                \n",
    "        output = self.linear(global_avg_pool_output_flat)\n",
    "        \n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rpslu5POxbjD"
   },
   "outputs": [],
   "source": [
    "net = PeleeNet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 12189
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 35784,
     "status": "ok",
     "timestamp": 1549779108241,
     "user": {
      "displayName": "PUBG호야",
      "photoUrl": "https://lh3.googleusercontent.com/-995djavMjjs/AAAAAAAAAAI/AAAAAAAAAGI/vwiBSSQLtiQ/s64/photo.jpg",
      "userId": "15725788610401702262"
     },
     "user_tz": -540
    },
    "id": "BxJpVdKDDrA4",
    "outputId": "652bb643-0b45-4e40-8d64-da6b0278b73a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PeleeNet(\n",
       "  (features): Sequential(\n",
       "    (StemBlock): StemBlock(\n",
       "      (conv_3x3_first): conv_bn_relu(\n",
       "        (conv): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (batch_norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "      )\n",
       "      (conv_1x1_left): conv_bn_relu(\n",
       "        (conv): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (batch_norm): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "      )\n",
       "      (conv_3x3_left): conv_bn_relu(\n",
       "        (conv): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (batch_norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "      )\n",
       "      (max_pool_right): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (conv_1x1_last): conv_bn_relu(\n",
       "        (conv): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (batch_norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "      )\n",
       "    )\n",
       "    (DenseBlock_1): DenseBlock(\n",
       "      (dense_layer_0): dense_layer(\n",
       "        (dense_left_way): Sequential(\n",
       "          (conv_1x1): conv_bn_relu(\n",
       "            (conv): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (batch_norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU(inplace)\n",
       "          )\n",
       "          (conv_3x3): conv_bn_relu(\n",
       "            (conv): Conv2d(64, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (batch_norm): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU(inplace)\n",
       "          )\n",
       "        )\n",
       "        (dense_right_way): Sequential(\n",
       "          (conv_1x1): conv_bn_relu(\n",
       "            (conv): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (batch_norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU(inplace)\n",
       "          )\n",
       "          (conv_3x3_1): conv_bn_relu(\n",
       "            (conv): Conv2d(64, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (batch_norm): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU(inplace)\n",
       "          )\n",
       "          (conv_3x3 2): conv_bn_relu(\n",
       "            (conv): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (batch_norm): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU(inplace)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (dense_layer_1): dense_layer(\n",
       "        (dense_left_way): Sequential(\n",
       "          (conv_1x1): conv_bn_relu(\n",
       "            (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (batch_norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU(inplace)\n",
       "          )\n",
       "          (conv_3x3): conv_bn_relu(\n",
       "            (conv): Conv2d(64, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (batch_norm): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU(inplace)\n",
       "          )\n",
       "        )\n",
       "        (dense_right_way): Sequential(\n",
       "          (conv_1x1): conv_bn_relu(\n",
       "            (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (batch_norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU(inplace)\n",
       "          )\n",
       "          (conv_3x3_1): conv_bn_relu(\n",
       "            (conv): Conv2d(64, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (batch_norm): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU(inplace)\n",
       "          )\n",
       "          (conv_3x3 2): conv_bn_relu(\n",
       "            (conv): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (batch_norm): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU(inplace)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (dense_layer_2): dense_layer(\n",
       "        (dense_left_way): Sequential(\n",
       "          (conv_1x1): conv_bn_relu(\n",
       "            (conv): Conv2d(96, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (batch_norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU(inplace)\n",
       "          )\n",
       "          (conv_3x3): conv_bn_relu(\n",
       "            (conv): Conv2d(64, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (batch_norm): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU(inplace)\n",
       "          )\n",
       "        )\n",
       "        (dense_right_way): Sequential(\n",
       "          (conv_1x1): conv_bn_relu(\n",
       "            (conv): Conv2d(96, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (batch_norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU(inplace)\n",
       "          )\n",
       "          (conv_3x3_1): conv_bn_relu(\n",
       "            (conv): Conv2d(64, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (batch_norm): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU(inplace)\n",
       "          )\n",
       "          (conv_3x3 2): conv_bn_relu(\n",
       "            (conv): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (batch_norm): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU(inplace)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (Transition_layer_1): Transition_layer(\n",
       "      (conv_1x1): conv_bn_relu(\n",
       "        (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (batch_norm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "      )\n",
       "      (avg_pool_2x2): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "    )\n",
       "    (DenseBlock_2): DenseBlock(\n",
       "      (dense_layer_0): dense_layer(\n",
       "        (dense_left_way): Sequential(\n",
       "          (conv_1x1): conv_bn_relu(\n",
       "            (conv): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (batch_norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU(inplace)\n",
       "          )\n",
       "          (conv_3x3): conv_bn_relu(\n",
       "            (conv): Conv2d(64, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (batch_norm): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU(inplace)\n",
       "          )\n",
       "        )\n",
       "        (dense_right_way): Sequential(\n",
       "          (conv_1x1): conv_bn_relu(\n",
       "            (conv): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (batch_norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU(inplace)\n",
       "          )\n",
       "          (conv_3x3_1): conv_bn_relu(\n",
       "            (conv): Conv2d(64, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (batch_norm): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU(inplace)\n",
       "          )\n",
       "          (conv_3x3 2): conv_bn_relu(\n",
       "            (conv): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (batch_norm): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU(inplace)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (dense_layer_1): dense_layer(\n",
       "        (dense_left_way): Sequential(\n",
       "          (conv_1x1): conv_bn_relu(\n",
       "            (conv): Conv2d(160, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (batch_norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU(inplace)\n",
       "          )\n",
       "          (conv_3x3): conv_bn_relu(\n",
       "            (conv): Conv2d(64, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (batch_norm): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU(inplace)\n",
       "          )\n",
       "        )\n",
       "        (dense_right_way): Sequential(\n",
       "          (conv_1x1): conv_bn_relu(\n",
       "            (conv): Conv2d(160, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (batch_norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU(inplace)\n",
       "          )\n",
       "          (conv_3x3_1): conv_bn_relu(\n",
       "            (conv): Conv2d(64, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (batch_norm): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU(inplace)\n",
       "          )\n",
       "          (conv_3x3 2): conv_bn_relu(\n",
       "            (conv): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (batch_norm): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU(inplace)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (dense_layer_2): dense_layer(\n",
       "        (dense_left_way): Sequential(\n",
       "          (conv_1x1): conv_bn_relu(\n",
       "            (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (batch_norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU(inplace)\n",
       "          )\n",
       "          (conv_3x3): conv_bn_relu(\n",
       "            (conv): Conv2d(64, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (batch_norm): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU(inplace)\n",
       "          )\n",
       "        )\n",
       "        (dense_right_way): Sequential(\n",
       "          (conv_1x1): conv_bn_relu(\n",
       "            (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (batch_norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU(inplace)\n",
       "          )\n",
       "          (conv_3x3_1): conv_bn_relu(\n",
       "            (conv): Conv2d(64, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (batch_norm): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU(inplace)\n",
       "          )\n",
       "          (conv_3x3 2): conv_bn_relu(\n",
       "            (conv): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (batch_norm): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU(inplace)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (dense_layer_3): dense_layer(\n",
       "        (dense_left_way): Sequential(\n",
       "          (conv_1x1): conv_bn_relu(\n",
       "            (conv): Conv2d(224, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (batch_norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU(inplace)\n",
       "          )\n",
       "          (conv_3x3): conv_bn_relu(\n",
       "            (conv): Conv2d(64, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (batch_norm): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU(inplace)\n",
       "          )\n",
       "        )\n",
       "        (dense_right_way): Sequential(\n",
       "          (conv_1x1): conv_bn_relu(\n",
       "            (conv): Conv2d(224, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (batch_norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU(inplace)\n",
       "          )\n",
       "          (conv_3x3_1): conv_bn_relu(\n",
       "            (conv): Conv2d(64, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (batch_norm): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU(inplace)\n",
       "          )\n",
       "          (conv_3x3 2): conv_bn_relu(\n",
       "            (conv): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (batch_norm): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU(inplace)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (Transition_layer_2): Transition_layer(\n",
       "      (conv_1x1): conv_bn_relu(\n",
       "        (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (batch_norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "      )\n",
       "      (avg_pool_2x2): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "    )\n",
       "    (DenseBlock_3): DenseBlock(\n",
       "      (dense_layer_0): dense_layer(\n",
       "        (dense_left_way): Sequential(\n",
       "          (conv_1x1): conv_bn_relu(\n",
       "            (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (batch_norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU(inplace)\n",
       "          )\n",
       "          (conv_3x3): conv_bn_relu(\n",
       "            (conv): Conv2d(64, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (batch_norm): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU(inplace)\n",
       "          )\n",
       "        )\n",
       "        (dense_right_way): Sequential(\n",
       "          (conv_1x1): conv_bn_relu(\n",
       "            (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (batch_norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU(inplace)\n",
       "          )\n",
       "          (conv_3x3_1): conv_bn_relu(\n",
       "            (conv): Conv2d(64, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (batch_norm): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU(inplace)\n",
       "          )\n",
       "          (conv_3x3 2): conv_bn_relu(\n",
       "            (conv): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (batch_norm): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU(inplace)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (dense_layer_1): dense_layer(\n",
       "        (dense_left_way): Sequential(\n",
       "          (conv_1x1): conv_bn_relu(\n",
       "            (conv): Conv2d(288, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (batch_norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU(inplace)\n",
       "          )\n",
       "          (conv_3x3): conv_bn_relu(\n",
       "            (conv): Conv2d(64, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (batch_norm): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU(inplace)\n",
       "          )\n",
       "        )\n",
       "        (dense_right_way): Sequential(\n",
       "          (conv_1x1): conv_bn_relu(\n",
       "            (conv): Conv2d(288, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (batch_norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU(inplace)\n",
       "          )\n",
       "          (conv_3x3_1): conv_bn_relu(\n",
       "            (conv): Conv2d(64, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (batch_norm): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU(inplace)\n",
       "          )\n",
       "          (conv_3x3 2): conv_bn_relu(\n",
       "            (conv): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (batch_norm): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU(inplace)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (dense_layer_2): dense_layer(\n",
       "        (dense_left_way): Sequential(\n",
       "          (conv_1x1): conv_bn_relu(\n",
       "            (conv): Conv2d(320, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (batch_norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU(inplace)\n",
       "          )\n",
       "          (conv_3x3): conv_bn_relu(\n",
       "            (conv): Conv2d(64, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (batch_norm): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU(inplace)\n",
       "          )\n",
       "        )\n",
       "        (dense_right_way): Sequential(\n",
       "          (conv_1x1): conv_bn_relu(\n",
       "            (conv): Conv2d(320, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (batch_norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU(inplace)\n",
       "          )\n",
       "          (conv_3x3_1): conv_bn_relu(\n",
       "            (conv): Conv2d(64, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (batch_norm): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU(inplace)\n",
       "          )\n",
       "          (conv_3x3 2): conv_bn_relu(\n",
       "            (conv): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (batch_norm): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU(inplace)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (dense_layer_3): dense_layer(\n",
       "        (dense_left_way): Sequential(\n",
       "          (conv_1x1): conv_bn_relu(\n",
       "            (conv): Conv2d(352, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (batch_norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU(inplace)\n",
       "          )\n",
       "          (conv_3x3): conv_bn_relu(\n",
       "            (conv): Conv2d(64, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (batch_norm): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU(inplace)\n",
       "          )\n",
       "        )\n",
       "        (dense_right_way): Sequential(\n",
       "          (conv_1x1): conv_bn_relu(\n",
       "            (conv): Conv2d(352, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (batch_norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU(inplace)\n",
       "          )\n",
       "          (conv_3x3_1): conv_bn_relu(\n",
       "            (conv): Conv2d(64, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (batch_norm): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU(inplace)\n",
       "          )\n",
       "          (conv_3x3 2): conv_bn_relu(\n",
       "            (conv): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (batch_norm): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU(inplace)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (dense_layer_4): dense_layer(\n",
       "        (dense_left_way): Sequential(\n",
       "          (conv_1x1): conv_bn_relu(\n",
       "            (conv): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (batch_norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU(inplace)\n",
       "          )\n",
       "          (conv_3x3): conv_bn_relu(\n",
       "            (conv): Conv2d(64, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (batch_norm): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU(inplace)\n",
       "          )\n",
       "        )\n",
       "        (dense_right_way): Sequential(\n",
       "          (conv_1x1): conv_bn_relu(\n",
       "            (conv): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (batch_norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU(inplace)\n",
       "          )\n",
       "          (conv_3x3_1): conv_bn_relu(\n",
       "            (conv): Conv2d(64, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (batch_norm): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU(inplace)\n",
       "          )\n",
       "          (conv_3x3 2): conv_bn_relu(\n",
       "            (conv): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (batch_norm): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU(inplace)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (dense_layer_5): dense_layer(\n",
       "        (dense_left_way): Sequential(\n",
       "          (conv_1x1): conv_bn_relu(\n",
       "            (conv): Conv2d(416, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (batch_norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU(inplace)\n",
       "          )\n",
       "          (conv_3x3): conv_bn_relu(\n",
       "            (conv): Conv2d(64, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (batch_norm): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU(inplace)\n",
       "          )\n",
       "        )\n",
       "        (dense_right_way): Sequential(\n",
       "          (conv_1x1): conv_bn_relu(\n",
       "            (conv): Conv2d(416, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (batch_norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU(inplace)\n",
       "          )\n",
       "          (conv_3x3_1): conv_bn_relu(\n",
       "            (conv): Conv2d(64, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (batch_norm): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU(inplace)\n",
       "          )\n",
       "          (conv_3x3 2): conv_bn_relu(\n",
       "            (conv): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (batch_norm): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU(inplace)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (dense_layer_6): dense_layer(\n",
       "        (dense_left_way): Sequential(\n",
       "          (conv_1x1): conv_bn_relu(\n",
       "            (conv): Conv2d(448, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (batch_norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU(inplace)\n",
       "          )\n",
       "          (conv_3x3): conv_bn_relu(\n",
       "            (conv): Conv2d(64, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (batch_norm): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU(inplace)\n",
       "          )\n",
       "        )\n",
       "        (dense_right_way): Sequential(\n",
       "          (conv_1x1): conv_bn_relu(\n",
       "            (conv): Conv2d(448, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (batch_norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU(inplace)\n",
       "          )\n",
       "          (conv_3x3_1): conv_bn_relu(\n",
       "            (conv): Conv2d(64, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (batch_norm): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU(inplace)\n",
       "          )\n",
       "          (conv_3x3 2): conv_bn_relu(\n",
       "            (conv): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (batch_norm): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU(inplace)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (dense_layer_7): dense_layer(\n",
       "        (dense_left_way): Sequential(\n",
       "          (conv_1x1): conv_bn_relu(\n",
       "            (conv): Conv2d(480, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (batch_norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU(inplace)\n",
       "          )\n",
       "          (conv_3x3): conv_bn_relu(\n",
       "            (conv): Conv2d(64, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (batch_norm): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU(inplace)\n",
       "          )\n",
       "        )\n",
       "        (dense_right_way): Sequential(\n",
       "          (conv_1x1): conv_bn_relu(\n",
       "            (conv): Conv2d(480, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (batch_norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU(inplace)\n",
       "          )\n",
       "          (conv_3x3_1): conv_bn_relu(\n",
       "            (conv): Conv2d(64, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (batch_norm): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU(inplace)\n",
       "          )\n",
       "          (conv_3x3 2): conv_bn_relu(\n",
       "            (conv): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (batch_norm): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU(inplace)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (Transition_layer_3): Transition_layer(\n",
       "      (conv_1x1): conv_bn_relu(\n",
       "        (conv): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (batch_norm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "      )\n",
       "      (avg_pool_2x2): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "    )\n",
       "    (DenseBlock_4): DenseBlock(\n",
       "      (dense_layer_0): dense_layer(\n",
       "        (dense_left_way): Sequential(\n",
       "          (conv_1x1): conv_bn_relu(\n",
       "            (conv): Conv2d(512, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (batch_norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU(inplace)\n",
       "          )\n",
       "          (conv_3x3): conv_bn_relu(\n",
       "            (conv): Conv2d(64, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (batch_norm): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU(inplace)\n",
       "          )\n",
       "        )\n",
       "        (dense_right_way): Sequential(\n",
       "          (conv_1x1): conv_bn_relu(\n",
       "            (conv): Conv2d(512, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (batch_norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU(inplace)\n",
       "          )\n",
       "          (conv_3x3_1): conv_bn_relu(\n",
       "            (conv): Conv2d(64, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (batch_norm): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU(inplace)\n",
       "          )\n",
       "          (conv_3x3 2): conv_bn_relu(\n",
       "            (conv): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (batch_norm): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU(inplace)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (dense_layer_1): dense_layer(\n",
       "        (dense_left_way): Sequential(\n",
       "          (conv_1x1): conv_bn_relu(\n",
       "            (conv): Conv2d(544, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (batch_norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU(inplace)\n",
       "          )\n",
       "          (conv_3x3): conv_bn_relu(\n",
       "            (conv): Conv2d(64, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (batch_norm): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU(inplace)\n",
       "          )\n",
       "        )\n",
       "        (dense_right_way): Sequential(\n",
       "          (conv_1x1): conv_bn_relu(\n",
       "            (conv): Conv2d(544, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (batch_norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU(inplace)\n",
       "          )\n",
       "          (conv_3x3_1): conv_bn_relu(\n",
       "            (conv): Conv2d(64, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (batch_norm): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU(inplace)\n",
       "          )\n",
       "          (conv_3x3 2): conv_bn_relu(\n",
       "            (conv): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (batch_norm): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU(inplace)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (dense_layer_2): dense_layer(\n",
       "        (dense_left_way): Sequential(\n",
       "          (conv_1x1): conv_bn_relu(\n",
       "            (conv): Conv2d(576, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (batch_norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU(inplace)\n",
       "          )\n",
       "          (conv_3x3): conv_bn_relu(\n",
       "            (conv): Conv2d(64, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (batch_norm): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU(inplace)\n",
       "          )\n",
       "        )\n",
       "        (dense_right_way): Sequential(\n",
       "          (conv_1x1): conv_bn_relu(\n",
       "            (conv): Conv2d(576, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (batch_norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU(inplace)\n",
       "          )\n",
       "          (conv_3x3_1): conv_bn_relu(\n",
       "            (conv): Conv2d(64, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (batch_norm): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU(inplace)\n",
       "          )\n",
       "          (conv_3x3 2): conv_bn_relu(\n",
       "            (conv): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (batch_norm): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU(inplace)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (dense_layer_3): dense_layer(\n",
       "        (dense_left_way): Sequential(\n",
       "          (conv_1x1): conv_bn_relu(\n",
       "            (conv): Conv2d(608, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (batch_norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU(inplace)\n",
       "          )\n",
       "          (conv_3x3): conv_bn_relu(\n",
       "            (conv): Conv2d(64, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (batch_norm): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU(inplace)\n",
       "          )\n",
       "        )\n",
       "        (dense_right_way): Sequential(\n",
       "          (conv_1x1): conv_bn_relu(\n",
       "            (conv): Conv2d(608, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (batch_norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU(inplace)\n",
       "          )\n",
       "          (conv_3x3_1): conv_bn_relu(\n",
       "            (conv): Conv2d(64, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (batch_norm): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU(inplace)\n",
       "          )\n",
       "          (conv_3x3 2): conv_bn_relu(\n",
       "            (conv): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (batch_norm): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU(inplace)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (dense_layer_4): dense_layer(\n",
       "        (dense_left_way): Sequential(\n",
       "          (conv_1x1): conv_bn_relu(\n",
       "            (conv): Conv2d(640, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (batch_norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU(inplace)\n",
       "          )\n",
       "          (conv_3x3): conv_bn_relu(\n",
       "            (conv): Conv2d(64, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (batch_norm): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU(inplace)\n",
       "          )\n",
       "        )\n",
       "        (dense_right_way): Sequential(\n",
       "          (conv_1x1): conv_bn_relu(\n",
       "            (conv): Conv2d(640, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (batch_norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU(inplace)\n",
       "          )\n",
       "          (conv_3x3_1): conv_bn_relu(\n",
       "            (conv): Conv2d(64, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (batch_norm): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU(inplace)\n",
       "          )\n",
       "          (conv_3x3 2): conv_bn_relu(\n",
       "            (conv): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (batch_norm): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU(inplace)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (dense_layer_5): dense_layer(\n",
       "        (dense_left_way): Sequential(\n",
       "          (conv_1x1): conv_bn_relu(\n",
       "            (conv): Conv2d(672, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (batch_norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU(inplace)\n",
       "          )\n",
       "          (conv_3x3): conv_bn_relu(\n",
       "            (conv): Conv2d(64, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (batch_norm): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU(inplace)\n",
       "          )\n",
       "        )\n",
       "        (dense_right_way): Sequential(\n",
       "          (conv_1x1): conv_bn_relu(\n",
       "            (conv): Conv2d(672, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (batch_norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU(inplace)\n",
       "          )\n",
       "          (conv_3x3_1): conv_bn_relu(\n",
       "            (conv): Conv2d(64, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (batch_norm): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU(inplace)\n",
       "          )\n",
       "          (conv_3x3 2): conv_bn_relu(\n",
       "            (conv): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (batch_norm): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU(inplace)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (Transition_layer_4): conv_bn_relu(\n",
       "      (conv): Conv2d(704, 704, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (batch_norm): BatchNorm2d(704, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "    )\n",
       "  )\n",
       "  (linear): Linear(in_features=704, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 13,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 8381
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 36294,
     "status": "ok",
     "timestamp": 1549779108764,
     "user": {
      "displayName": "PUBG호야",
      "photoUrl": "https://lh3.googleusercontent.com/-995djavMjjs/AAAAAAAAAAI/AAAAAAAAAGI/vwiBSSQLtiQ/s64/photo.jpg",
      "userId": "15725788610401702262"
     },
     "user_tz": -540
    },
    "id": "3qYqt69xDfrP",
    "outputId": "1400db13-0547-4a30-fdad-e16fc5d47d97"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1         [-1, 32, 112, 112]             864\n",
      "       BatchNorm2d-2         [-1, 32, 112, 112]              64\n",
      "              ReLU-3         [-1, 32, 112, 112]               0\n",
      "      conv_bn_relu-4         [-1, 32, 112, 112]               0\n",
      "            Conv2d-5         [-1, 16, 112, 112]             512\n",
      "       BatchNorm2d-6         [-1, 16, 112, 112]              32\n",
      "              ReLU-7         [-1, 16, 112, 112]               0\n",
      "      conv_bn_relu-8         [-1, 16, 112, 112]               0\n",
      "            Conv2d-9           [-1, 32, 56, 56]           4,608\n",
      "      BatchNorm2d-10           [-1, 32, 56, 56]              64\n",
      "             ReLU-11           [-1, 32, 56, 56]               0\n",
      "     conv_bn_relu-12           [-1, 32, 56, 56]               0\n",
      "        MaxPool2d-13           [-1, 32, 56, 56]               0\n",
      "           Conv2d-14           [-1, 32, 56, 56]           2,048\n",
      "      BatchNorm2d-15           [-1, 32, 56, 56]              64\n",
      "             ReLU-16           [-1, 32, 56, 56]               0\n",
      "     conv_bn_relu-17           [-1, 32, 56, 56]               0\n",
      "        StemBlock-18           [-1, 32, 56, 56]               0\n",
      "           Conv2d-19           [-1, 64, 56, 56]           2,048\n",
      "      BatchNorm2d-20           [-1, 64, 56, 56]             128\n",
      "             ReLU-21           [-1, 64, 56, 56]               0\n",
      "     conv_bn_relu-22           [-1, 64, 56, 56]               0\n",
      "           Conv2d-23           [-1, 16, 56, 56]           9,216\n",
      "      BatchNorm2d-24           [-1, 16, 56, 56]              32\n",
      "             ReLU-25           [-1, 16, 56, 56]               0\n",
      "     conv_bn_relu-26           [-1, 16, 56, 56]               0\n",
      "           Conv2d-27           [-1, 64, 56, 56]           2,048\n",
      "      BatchNorm2d-28           [-1, 64, 56, 56]             128\n",
      "             ReLU-29           [-1, 64, 56, 56]               0\n",
      "     conv_bn_relu-30           [-1, 64, 56, 56]               0\n",
      "           Conv2d-31           [-1, 16, 56, 56]           9,216\n",
      "      BatchNorm2d-32           [-1, 16, 56, 56]              32\n",
      "             ReLU-33           [-1, 16, 56, 56]               0\n",
      "     conv_bn_relu-34           [-1, 16, 56, 56]               0\n",
      "           Conv2d-35           [-1, 16, 56, 56]           2,304\n",
      "      BatchNorm2d-36           [-1, 16, 56, 56]              32\n",
      "             ReLU-37           [-1, 16, 56, 56]               0\n",
      "     conv_bn_relu-38           [-1, 16, 56, 56]               0\n",
      "      dense_layer-39           [-1, 64, 56, 56]               0\n",
      "           Conv2d-40           [-1, 64, 56, 56]           4,096\n",
      "      BatchNorm2d-41           [-1, 64, 56, 56]             128\n",
      "             ReLU-42           [-1, 64, 56, 56]               0\n",
      "     conv_bn_relu-43           [-1, 64, 56, 56]               0\n",
      "           Conv2d-44           [-1, 16, 56, 56]           9,216\n",
      "      BatchNorm2d-45           [-1, 16, 56, 56]              32\n",
      "             ReLU-46           [-1, 16, 56, 56]               0\n",
      "     conv_bn_relu-47           [-1, 16, 56, 56]               0\n",
      "           Conv2d-48           [-1, 64, 56, 56]           4,096\n",
      "      BatchNorm2d-49           [-1, 64, 56, 56]             128\n",
      "             ReLU-50           [-1, 64, 56, 56]               0\n",
      "     conv_bn_relu-51           [-1, 64, 56, 56]               0\n",
      "           Conv2d-52           [-1, 16, 56, 56]           9,216\n",
      "      BatchNorm2d-53           [-1, 16, 56, 56]              32\n",
      "             ReLU-54           [-1, 16, 56, 56]               0\n",
      "     conv_bn_relu-55           [-1, 16, 56, 56]               0\n",
      "           Conv2d-56           [-1, 16, 56, 56]           2,304\n",
      "      BatchNorm2d-57           [-1, 16, 56, 56]              32\n",
      "             ReLU-58           [-1, 16, 56, 56]               0\n",
      "     conv_bn_relu-59           [-1, 16, 56, 56]               0\n",
      "      dense_layer-60           [-1, 96, 56, 56]               0\n",
      "           Conv2d-61           [-1, 64, 56, 56]           6,144\n",
      "      BatchNorm2d-62           [-1, 64, 56, 56]             128\n",
      "             ReLU-63           [-1, 64, 56, 56]               0\n",
      "     conv_bn_relu-64           [-1, 64, 56, 56]               0\n",
      "           Conv2d-65           [-1, 16, 56, 56]           9,216\n",
      "      BatchNorm2d-66           [-1, 16, 56, 56]              32\n",
      "             ReLU-67           [-1, 16, 56, 56]               0\n",
      "     conv_bn_relu-68           [-1, 16, 56, 56]               0\n",
      "           Conv2d-69           [-1, 64, 56, 56]           6,144\n",
      "      BatchNorm2d-70           [-1, 64, 56, 56]             128\n",
      "             ReLU-71           [-1, 64, 56, 56]               0\n",
      "     conv_bn_relu-72           [-1, 64, 56, 56]               0\n",
      "           Conv2d-73           [-1, 16, 56, 56]           9,216\n",
      "      BatchNorm2d-74           [-1, 16, 56, 56]              32\n",
      "             ReLU-75           [-1, 16, 56, 56]               0\n",
      "     conv_bn_relu-76           [-1, 16, 56, 56]               0\n",
      "           Conv2d-77           [-1, 16, 56, 56]           2,304\n",
      "      BatchNorm2d-78           [-1, 16, 56, 56]              32\n",
      "             ReLU-79           [-1, 16, 56, 56]               0\n",
      "     conv_bn_relu-80           [-1, 16, 56, 56]               0\n",
      "      dense_layer-81          [-1, 128, 56, 56]               0\n",
      "           Conv2d-82          [-1, 128, 56, 56]          16,384\n",
      "      BatchNorm2d-83          [-1, 128, 56, 56]             256\n",
      "             ReLU-84          [-1, 128, 56, 56]               0\n",
      "     conv_bn_relu-85          [-1, 128, 56, 56]               0\n",
      "        AvgPool2d-86          [-1, 128, 28, 28]               0\n",
      "           Conv2d-87           [-1, 64, 28, 28]           8,192\n",
      "      BatchNorm2d-88           [-1, 64, 28, 28]             128\n",
      "             ReLU-89           [-1, 64, 28, 28]               0\n",
      "     conv_bn_relu-90           [-1, 64, 28, 28]               0\n",
      "           Conv2d-91           [-1, 16, 28, 28]           9,216\n",
      "      BatchNorm2d-92           [-1, 16, 28, 28]              32\n",
      "             ReLU-93           [-1, 16, 28, 28]               0\n",
      "     conv_bn_relu-94           [-1, 16, 28, 28]               0\n",
      "           Conv2d-95           [-1, 64, 28, 28]           8,192\n",
      "      BatchNorm2d-96           [-1, 64, 28, 28]             128\n",
      "             ReLU-97           [-1, 64, 28, 28]               0\n",
      "     conv_bn_relu-98           [-1, 64, 28, 28]               0\n",
      "           Conv2d-99           [-1, 16, 28, 28]           9,216\n",
      "     BatchNorm2d-100           [-1, 16, 28, 28]              32\n",
      "            ReLU-101           [-1, 16, 28, 28]               0\n",
      "    conv_bn_relu-102           [-1, 16, 28, 28]               0\n",
      "          Conv2d-103           [-1, 16, 28, 28]           2,304\n",
      "     BatchNorm2d-104           [-1, 16, 28, 28]              32\n",
      "            ReLU-105           [-1, 16, 28, 28]               0\n",
      "    conv_bn_relu-106           [-1, 16, 28, 28]               0\n",
      "     dense_layer-107          [-1, 160, 28, 28]               0\n",
      "          Conv2d-108           [-1, 64, 28, 28]          10,240\n",
      "     BatchNorm2d-109           [-1, 64, 28, 28]             128\n",
      "            ReLU-110           [-1, 64, 28, 28]               0\n",
      "    conv_bn_relu-111           [-1, 64, 28, 28]               0\n",
      "          Conv2d-112           [-1, 16, 28, 28]           9,216\n",
      "     BatchNorm2d-113           [-1, 16, 28, 28]              32\n",
      "            ReLU-114           [-1, 16, 28, 28]               0\n",
      "    conv_bn_relu-115           [-1, 16, 28, 28]               0\n",
      "          Conv2d-116           [-1, 64, 28, 28]          10,240\n",
      "     BatchNorm2d-117           [-1, 64, 28, 28]             128\n",
      "            ReLU-118           [-1, 64, 28, 28]               0\n",
      "    conv_bn_relu-119           [-1, 64, 28, 28]               0\n",
      "          Conv2d-120           [-1, 16, 28, 28]           9,216\n",
      "     BatchNorm2d-121           [-1, 16, 28, 28]              32\n",
      "            ReLU-122           [-1, 16, 28, 28]               0\n",
      "    conv_bn_relu-123           [-1, 16, 28, 28]               0\n",
      "          Conv2d-124           [-1, 16, 28, 28]           2,304\n",
      "     BatchNorm2d-125           [-1, 16, 28, 28]              32\n",
      "            ReLU-126           [-1, 16, 28, 28]               0\n",
      "    conv_bn_relu-127           [-1, 16, 28, 28]               0\n",
      "     dense_layer-128          [-1, 192, 28, 28]               0\n",
      "          Conv2d-129           [-1, 64, 28, 28]          12,288\n",
      "     BatchNorm2d-130           [-1, 64, 28, 28]             128\n",
      "            ReLU-131           [-1, 64, 28, 28]               0\n",
      "    conv_bn_relu-132           [-1, 64, 28, 28]               0\n",
      "          Conv2d-133           [-1, 16, 28, 28]           9,216\n",
      "     BatchNorm2d-134           [-1, 16, 28, 28]              32\n",
      "            ReLU-135           [-1, 16, 28, 28]               0\n",
      "    conv_bn_relu-136           [-1, 16, 28, 28]               0\n",
      "          Conv2d-137           [-1, 64, 28, 28]          12,288\n",
      "     BatchNorm2d-138           [-1, 64, 28, 28]             128\n",
      "            ReLU-139           [-1, 64, 28, 28]               0\n",
      "    conv_bn_relu-140           [-1, 64, 28, 28]               0\n",
      "          Conv2d-141           [-1, 16, 28, 28]           9,216\n",
      "     BatchNorm2d-142           [-1, 16, 28, 28]              32\n",
      "            ReLU-143           [-1, 16, 28, 28]               0\n",
      "    conv_bn_relu-144           [-1, 16, 28, 28]               0\n",
      "          Conv2d-145           [-1, 16, 28, 28]           2,304\n",
      "     BatchNorm2d-146           [-1, 16, 28, 28]              32\n",
      "            ReLU-147           [-1, 16, 28, 28]               0\n",
      "    conv_bn_relu-148           [-1, 16, 28, 28]               0\n",
      "     dense_layer-149          [-1, 224, 28, 28]               0\n",
      "          Conv2d-150           [-1, 64, 28, 28]          14,336\n",
      "     BatchNorm2d-151           [-1, 64, 28, 28]             128\n",
      "            ReLU-152           [-1, 64, 28, 28]               0\n",
      "    conv_bn_relu-153           [-1, 64, 28, 28]               0\n",
      "          Conv2d-154           [-1, 16, 28, 28]           9,216\n",
      "     BatchNorm2d-155           [-1, 16, 28, 28]              32\n",
      "            ReLU-156           [-1, 16, 28, 28]               0\n",
      "    conv_bn_relu-157           [-1, 16, 28, 28]               0\n",
      "          Conv2d-158           [-1, 64, 28, 28]          14,336\n",
      "     BatchNorm2d-159           [-1, 64, 28, 28]             128\n",
      "            ReLU-160           [-1, 64, 28, 28]               0\n",
      "    conv_bn_relu-161           [-1, 64, 28, 28]               0\n",
      "          Conv2d-162           [-1, 16, 28, 28]           9,216\n",
      "     BatchNorm2d-163           [-1, 16, 28, 28]              32\n",
      "            ReLU-164           [-1, 16, 28, 28]               0\n",
      "    conv_bn_relu-165           [-1, 16, 28, 28]               0\n",
      "          Conv2d-166           [-1, 16, 28, 28]           2,304\n",
      "     BatchNorm2d-167           [-1, 16, 28, 28]              32\n",
      "            ReLU-168           [-1, 16, 28, 28]               0\n",
      "    conv_bn_relu-169           [-1, 16, 28, 28]               0\n",
      "     dense_layer-170          [-1, 256, 28, 28]               0\n",
      "          Conv2d-171          [-1, 256, 28, 28]          65,536\n",
      "     BatchNorm2d-172          [-1, 256, 28, 28]             512\n",
      "            ReLU-173          [-1, 256, 28, 28]               0\n",
      "    conv_bn_relu-174          [-1, 256, 28, 28]               0\n",
      "       AvgPool2d-175          [-1, 256, 14, 14]               0\n",
      "          Conv2d-176           [-1, 64, 14, 14]          16,384\n",
      "     BatchNorm2d-177           [-1, 64, 14, 14]             128\n",
      "            ReLU-178           [-1, 64, 14, 14]               0\n",
      "    conv_bn_relu-179           [-1, 64, 14, 14]               0\n",
      "          Conv2d-180           [-1, 16, 14, 14]           9,216\n",
      "     BatchNorm2d-181           [-1, 16, 14, 14]              32\n",
      "            ReLU-182           [-1, 16, 14, 14]               0\n",
      "    conv_bn_relu-183           [-1, 16, 14, 14]               0\n",
      "          Conv2d-184           [-1, 64, 14, 14]          16,384\n",
      "     BatchNorm2d-185           [-1, 64, 14, 14]             128\n",
      "            ReLU-186           [-1, 64, 14, 14]               0\n",
      "    conv_bn_relu-187           [-1, 64, 14, 14]               0\n",
      "          Conv2d-188           [-1, 16, 14, 14]           9,216\n",
      "     BatchNorm2d-189           [-1, 16, 14, 14]              32\n",
      "            ReLU-190           [-1, 16, 14, 14]               0\n",
      "    conv_bn_relu-191           [-1, 16, 14, 14]               0\n",
      "          Conv2d-192           [-1, 16, 14, 14]           2,304\n",
      "     BatchNorm2d-193           [-1, 16, 14, 14]              32\n",
      "            ReLU-194           [-1, 16, 14, 14]               0\n",
      "    conv_bn_relu-195           [-1, 16, 14, 14]               0\n",
      "     dense_layer-196          [-1, 288, 14, 14]               0\n",
      "          Conv2d-197           [-1, 64, 14, 14]          18,432\n",
      "     BatchNorm2d-198           [-1, 64, 14, 14]             128\n",
      "            ReLU-199           [-1, 64, 14, 14]               0\n",
      "    conv_bn_relu-200           [-1, 64, 14, 14]               0\n",
      "          Conv2d-201           [-1, 16, 14, 14]           9,216\n",
      "     BatchNorm2d-202           [-1, 16, 14, 14]              32\n",
      "            ReLU-203           [-1, 16, 14, 14]               0\n",
      "    conv_bn_relu-204           [-1, 16, 14, 14]               0\n",
      "          Conv2d-205           [-1, 64, 14, 14]          18,432\n",
      "     BatchNorm2d-206           [-1, 64, 14, 14]             128\n",
      "            ReLU-207           [-1, 64, 14, 14]               0\n",
      "    conv_bn_relu-208           [-1, 64, 14, 14]               0\n",
      "          Conv2d-209           [-1, 16, 14, 14]           9,216\n",
      "     BatchNorm2d-210           [-1, 16, 14, 14]              32\n",
      "            ReLU-211           [-1, 16, 14, 14]               0\n",
      "    conv_bn_relu-212           [-1, 16, 14, 14]               0\n",
      "          Conv2d-213           [-1, 16, 14, 14]           2,304\n",
      "     BatchNorm2d-214           [-1, 16, 14, 14]              32\n",
      "            ReLU-215           [-1, 16, 14, 14]               0\n",
      "    conv_bn_relu-216           [-1, 16, 14, 14]               0\n",
      "     dense_layer-217          [-1, 320, 14, 14]               0\n",
      "          Conv2d-218           [-1, 64, 14, 14]          20,480\n",
      "     BatchNorm2d-219           [-1, 64, 14, 14]             128\n",
      "            ReLU-220           [-1, 64, 14, 14]               0\n",
      "    conv_bn_relu-221           [-1, 64, 14, 14]               0\n",
      "          Conv2d-222           [-1, 16, 14, 14]           9,216\n",
      "     BatchNorm2d-223           [-1, 16, 14, 14]              32\n",
      "            ReLU-224           [-1, 16, 14, 14]               0\n",
      "    conv_bn_relu-225           [-1, 16, 14, 14]               0\n",
      "          Conv2d-226           [-1, 64, 14, 14]          20,480\n",
      "     BatchNorm2d-227           [-1, 64, 14, 14]             128\n",
      "            ReLU-228           [-1, 64, 14, 14]               0\n",
      "    conv_bn_relu-229           [-1, 64, 14, 14]               0\n",
      "          Conv2d-230           [-1, 16, 14, 14]           9,216\n",
      "     BatchNorm2d-231           [-1, 16, 14, 14]              32\n",
      "            ReLU-232           [-1, 16, 14, 14]               0\n",
      "    conv_bn_relu-233           [-1, 16, 14, 14]               0\n",
      "          Conv2d-234           [-1, 16, 14, 14]           2,304\n",
      "     BatchNorm2d-235           [-1, 16, 14, 14]              32\n",
      "            ReLU-236           [-1, 16, 14, 14]               0\n",
      "    conv_bn_relu-237           [-1, 16, 14, 14]               0\n",
      "     dense_layer-238          [-1, 352, 14, 14]               0\n",
      "          Conv2d-239           [-1, 64, 14, 14]          22,528\n",
      "     BatchNorm2d-240           [-1, 64, 14, 14]             128\n",
      "            ReLU-241           [-1, 64, 14, 14]               0\n",
      "    conv_bn_relu-242           [-1, 64, 14, 14]               0\n",
      "          Conv2d-243           [-1, 16, 14, 14]           9,216\n",
      "     BatchNorm2d-244           [-1, 16, 14, 14]              32\n",
      "            ReLU-245           [-1, 16, 14, 14]               0\n",
      "    conv_bn_relu-246           [-1, 16, 14, 14]               0\n",
      "          Conv2d-247           [-1, 64, 14, 14]          22,528\n",
      "     BatchNorm2d-248           [-1, 64, 14, 14]             128\n",
      "            ReLU-249           [-1, 64, 14, 14]               0\n",
      "    conv_bn_relu-250           [-1, 64, 14, 14]               0\n",
      "          Conv2d-251           [-1, 16, 14, 14]           9,216\n",
      "     BatchNorm2d-252           [-1, 16, 14, 14]              32\n",
      "            ReLU-253           [-1, 16, 14, 14]               0\n",
      "    conv_bn_relu-254           [-1, 16, 14, 14]               0\n",
      "          Conv2d-255           [-1, 16, 14, 14]           2,304\n",
      "     BatchNorm2d-256           [-1, 16, 14, 14]              32\n",
      "            ReLU-257           [-1, 16, 14, 14]               0\n",
      "    conv_bn_relu-258           [-1, 16, 14, 14]               0\n",
      "     dense_layer-259          [-1, 384, 14, 14]               0\n",
      "          Conv2d-260           [-1, 64, 14, 14]          24,576\n",
      "     BatchNorm2d-261           [-1, 64, 14, 14]             128\n",
      "            ReLU-262           [-1, 64, 14, 14]               0\n",
      "    conv_bn_relu-263           [-1, 64, 14, 14]               0\n",
      "          Conv2d-264           [-1, 16, 14, 14]           9,216\n",
      "     BatchNorm2d-265           [-1, 16, 14, 14]              32\n",
      "            ReLU-266           [-1, 16, 14, 14]               0\n",
      "    conv_bn_relu-267           [-1, 16, 14, 14]               0\n",
      "          Conv2d-268           [-1, 64, 14, 14]          24,576\n",
      "     BatchNorm2d-269           [-1, 64, 14, 14]             128\n",
      "            ReLU-270           [-1, 64, 14, 14]               0\n",
      "    conv_bn_relu-271           [-1, 64, 14, 14]               0\n",
      "          Conv2d-272           [-1, 16, 14, 14]           9,216\n",
      "     BatchNorm2d-273           [-1, 16, 14, 14]              32\n",
      "            ReLU-274           [-1, 16, 14, 14]               0\n",
      "    conv_bn_relu-275           [-1, 16, 14, 14]               0\n",
      "          Conv2d-276           [-1, 16, 14, 14]           2,304\n",
      "     BatchNorm2d-277           [-1, 16, 14, 14]              32\n",
      "            ReLU-278           [-1, 16, 14, 14]               0\n",
      "    conv_bn_relu-279           [-1, 16, 14, 14]               0\n",
      "     dense_layer-280          [-1, 416, 14, 14]               0\n",
      "          Conv2d-281           [-1, 64, 14, 14]          26,624\n",
      "     BatchNorm2d-282           [-1, 64, 14, 14]             128\n",
      "            ReLU-283           [-1, 64, 14, 14]               0\n",
      "    conv_bn_relu-284           [-1, 64, 14, 14]               0\n",
      "          Conv2d-285           [-1, 16, 14, 14]           9,216\n",
      "     BatchNorm2d-286           [-1, 16, 14, 14]              32\n",
      "            ReLU-287           [-1, 16, 14, 14]               0\n",
      "    conv_bn_relu-288           [-1, 16, 14, 14]               0\n",
      "          Conv2d-289           [-1, 64, 14, 14]          26,624\n",
      "     BatchNorm2d-290           [-1, 64, 14, 14]             128\n",
      "            ReLU-291           [-1, 64, 14, 14]               0\n",
      "    conv_bn_relu-292           [-1, 64, 14, 14]               0\n",
      "          Conv2d-293           [-1, 16, 14, 14]           9,216\n",
      "     BatchNorm2d-294           [-1, 16, 14, 14]              32\n",
      "            ReLU-295           [-1, 16, 14, 14]               0\n",
      "    conv_bn_relu-296           [-1, 16, 14, 14]               0\n",
      "          Conv2d-297           [-1, 16, 14, 14]           2,304\n",
      "     BatchNorm2d-298           [-1, 16, 14, 14]              32\n",
      "            ReLU-299           [-1, 16, 14, 14]               0\n",
      "    conv_bn_relu-300           [-1, 16, 14, 14]               0\n",
      "     dense_layer-301          [-1, 448, 14, 14]               0\n",
      "          Conv2d-302           [-1, 64, 14, 14]          28,672\n",
      "     BatchNorm2d-303           [-1, 64, 14, 14]             128\n",
      "            ReLU-304           [-1, 64, 14, 14]               0\n",
      "    conv_bn_relu-305           [-1, 64, 14, 14]               0\n",
      "          Conv2d-306           [-1, 16, 14, 14]           9,216\n",
      "     BatchNorm2d-307           [-1, 16, 14, 14]              32\n",
      "            ReLU-308           [-1, 16, 14, 14]               0\n",
      "    conv_bn_relu-309           [-1, 16, 14, 14]               0\n",
      "          Conv2d-310           [-1, 64, 14, 14]          28,672\n",
      "     BatchNorm2d-311           [-1, 64, 14, 14]             128\n",
      "            ReLU-312           [-1, 64, 14, 14]               0\n",
      "    conv_bn_relu-313           [-1, 64, 14, 14]               0\n",
      "          Conv2d-314           [-1, 16, 14, 14]           9,216\n",
      "     BatchNorm2d-315           [-1, 16, 14, 14]              32\n",
      "            ReLU-316           [-1, 16, 14, 14]               0\n",
      "    conv_bn_relu-317           [-1, 16, 14, 14]               0\n",
      "          Conv2d-318           [-1, 16, 14, 14]           2,304\n",
      "     BatchNorm2d-319           [-1, 16, 14, 14]              32\n",
      "            ReLU-320           [-1, 16, 14, 14]               0\n",
      "    conv_bn_relu-321           [-1, 16, 14, 14]               0\n",
      "     dense_layer-322          [-1, 480, 14, 14]               0\n",
      "          Conv2d-323           [-1, 64, 14, 14]          30,720\n",
      "     BatchNorm2d-324           [-1, 64, 14, 14]             128\n",
      "            ReLU-325           [-1, 64, 14, 14]               0\n",
      "    conv_bn_relu-326           [-1, 64, 14, 14]               0\n",
      "          Conv2d-327           [-1, 16, 14, 14]           9,216\n",
      "     BatchNorm2d-328           [-1, 16, 14, 14]              32\n",
      "            ReLU-329           [-1, 16, 14, 14]               0\n",
      "    conv_bn_relu-330           [-1, 16, 14, 14]               0\n",
      "          Conv2d-331           [-1, 64, 14, 14]          30,720\n",
      "     BatchNorm2d-332           [-1, 64, 14, 14]             128\n",
      "            ReLU-333           [-1, 64, 14, 14]               0\n",
      "    conv_bn_relu-334           [-1, 64, 14, 14]               0\n",
      "          Conv2d-335           [-1, 16, 14, 14]           9,216\n",
      "     BatchNorm2d-336           [-1, 16, 14, 14]              32\n",
      "            ReLU-337           [-1, 16, 14, 14]               0\n",
      "    conv_bn_relu-338           [-1, 16, 14, 14]               0\n",
      "          Conv2d-339           [-1, 16, 14, 14]           2,304\n",
      "     BatchNorm2d-340           [-1, 16, 14, 14]              32\n",
      "            ReLU-341           [-1, 16, 14, 14]               0\n",
      "    conv_bn_relu-342           [-1, 16, 14, 14]               0\n",
      "     dense_layer-343          [-1, 512, 14, 14]               0\n",
      "          Conv2d-344          [-1, 512, 14, 14]         262,144\n",
      "     BatchNorm2d-345          [-1, 512, 14, 14]           1,024\n",
      "            ReLU-346          [-1, 512, 14, 14]               0\n",
      "    conv_bn_relu-347          [-1, 512, 14, 14]               0\n",
      "       AvgPool2d-348            [-1, 512, 7, 7]               0\n",
      "          Conv2d-349             [-1, 64, 7, 7]          32,768\n",
      "     BatchNorm2d-350             [-1, 64, 7, 7]             128\n",
      "            ReLU-351             [-1, 64, 7, 7]               0\n",
      "    conv_bn_relu-352             [-1, 64, 7, 7]               0\n",
      "          Conv2d-353             [-1, 16, 7, 7]           9,216\n",
      "     BatchNorm2d-354             [-1, 16, 7, 7]              32\n",
      "            ReLU-355             [-1, 16, 7, 7]               0\n",
      "    conv_bn_relu-356             [-1, 16, 7, 7]               0\n",
      "          Conv2d-357             [-1, 64, 7, 7]          32,768\n",
      "     BatchNorm2d-358             [-1, 64, 7, 7]             128\n",
      "            ReLU-359             [-1, 64, 7, 7]               0\n",
      "    conv_bn_relu-360             [-1, 64, 7, 7]               0\n",
      "          Conv2d-361             [-1, 16, 7, 7]           9,216\n",
      "     BatchNorm2d-362             [-1, 16, 7, 7]              32\n",
      "            ReLU-363             [-1, 16, 7, 7]               0\n",
      "    conv_bn_relu-364             [-1, 16, 7, 7]               0\n",
      "          Conv2d-365             [-1, 16, 7, 7]           2,304\n",
      "     BatchNorm2d-366             [-1, 16, 7, 7]              32\n",
      "            ReLU-367             [-1, 16, 7, 7]               0\n",
      "    conv_bn_relu-368             [-1, 16, 7, 7]               0\n",
      "     dense_layer-369            [-1, 544, 7, 7]               0\n",
      "          Conv2d-370             [-1, 64, 7, 7]          34,816\n",
      "     BatchNorm2d-371             [-1, 64, 7, 7]             128\n",
      "            ReLU-372             [-1, 64, 7, 7]               0\n",
      "    conv_bn_relu-373             [-1, 64, 7, 7]               0\n",
      "          Conv2d-374             [-1, 16, 7, 7]           9,216\n",
      "     BatchNorm2d-375             [-1, 16, 7, 7]              32\n",
      "            ReLU-376             [-1, 16, 7, 7]               0\n",
      "    conv_bn_relu-377             [-1, 16, 7, 7]               0\n",
      "          Conv2d-378             [-1, 64, 7, 7]          34,816\n",
      "     BatchNorm2d-379             [-1, 64, 7, 7]             128\n",
      "            ReLU-380             [-1, 64, 7, 7]               0\n",
      "    conv_bn_relu-381             [-1, 64, 7, 7]               0\n",
      "          Conv2d-382             [-1, 16, 7, 7]           9,216\n",
      "     BatchNorm2d-383             [-1, 16, 7, 7]              32\n",
      "            ReLU-384             [-1, 16, 7, 7]               0\n",
      "    conv_bn_relu-385             [-1, 16, 7, 7]               0\n",
      "          Conv2d-386             [-1, 16, 7, 7]           2,304\n",
      "     BatchNorm2d-387             [-1, 16, 7, 7]              32\n",
      "            ReLU-388             [-1, 16, 7, 7]               0\n",
      "    conv_bn_relu-389             [-1, 16, 7, 7]               0\n",
      "     dense_layer-390            [-1, 576, 7, 7]               0\n",
      "          Conv2d-391             [-1, 64, 7, 7]          36,864\n",
      "     BatchNorm2d-392             [-1, 64, 7, 7]             128\n",
      "            ReLU-393             [-1, 64, 7, 7]               0\n",
      "    conv_bn_relu-394             [-1, 64, 7, 7]               0\n",
      "          Conv2d-395             [-1, 16, 7, 7]           9,216\n",
      "     BatchNorm2d-396             [-1, 16, 7, 7]              32\n",
      "            ReLU-397             [-1, 16, 7, 7]               0\n",
      "    conv_bn_relu-398             [-1, 16, 7, 7]               0\n",
      "          Conv2d-399             [-1, 64, 7, 7]          36,864\n",
      "     BatchNorm2d-400             [-1, 64, 7, 7]             128\n",
      "            ReLU-401             [-1, 64, 7, 7]               0\n",
      "    conv_bn_relu-402             [-1, 64, 7, 7]               0\n",
      "          Conv2d-403             [-1, 16, 7, 7]           9,216\n",
      "     BatchNorm2d-404             [-1, 16, 7, 7]              32\n",
      "            ReLU-405             [-1, 16, 7, 7]               0\n",
      "    conv_bn_relu-406             [-1, 16, 7, 7]               0\n",
      "          Conv2d-407             [-1, 16, 7, 7]           2,304\n",
      "     BatchNorm2d-408             [-1, 16, 7, 7]              32\n",
      "            ReLU-409             [-1, 16, 7, 7]               0\n",
      "    conv_bn_relu-410             [-1, 16, 7, 7]               0\n",
      "     dense_layer-411            [-1, 608, 7, 7]               0\n",
      "          Conv2d-412             [-1, 64, 7, 7]          38,912\n",
      "     BatchNorm2d-413             [-1, 64, 7, 7]             128\n",
      "            ReLU-414             [-1, 64, 7, 7]               0\n",
      "    conv_bn_relu-415             [-1, 64, 7, 7]               0\n",
      "          Conv2d-416             [-1, 16, 7, 7]           9,216\n",
      "     BatchNorm2d-417             [-1, 16, 7, 7]              32\n",
      "            ReLU-418             [-1, 16, 7, 7]               0\n",
      "    conv_bn_relu-419             [-1, 16, 7, 7]               0\n",
      "          Conv2d-420             [-1, 64, 7, 7]          38,912\n",
      "     BatchNorm2d-421             [-1, 64, 7, 7]             128\n",
      "            ReLU-422             [-1, 64, 7, 7]               0\n",
      "    conv_bn_relu-423             [-1, 64, 7, 7]               0\n",
      "          Conv2d-424             [-1, 16, 7, 7]           9,216\n",
      "     BatchNorm2d-425             [-1, 16, 7, 7]              32\n",
      "            ReLU-426             [-1, 16, 7, 7]               0\n",
      "    conv_bn_relu-427             [-1, 16, 7, 7]               0\n",
      "          Conv2d-428             [-1, 16, 7, 7]           2,304\n",
      "     BatchNorm2d-429             [-1, 16, 7, 7]              32\n",
      "            ReLU-430             [-1, 16, 7, 7]               0\n",
      "    conv_bn_relu-431             [-1, 16, 7, 7]               0\n",
      "     dense_layer-432            [-1, 640, 7, 7]               0\n",
      "          Conv2d-433             [-1, 64, 7, 7]          40,960\n",
      "     BatchNorm2d-434             [-1, 64, 7, 7]             128\n",
      "            ReLU-435             [-1, 64, 7, 7]               0\n",
      "    conv_bn_relu-436             [-1, 64, 7, 7]               0\n",
      "          Conv2d-437             [-1, 16, 7, 7]           9,216\n",
      "     BatchNorm2d-438             [-1, 16, 7, 7]              32\n",
      "            ReLU-439             [-1, 16, 7, 7]               0\n",
      "    conv_bn_relu-440             [-1, 16, 7, 7]               0\n",
      "          Conv2d-441             [-1, 64, 7, 7]          40,960\n",
      "     BatchNorm2d-442             [-1, 64, 7, 7]             128\n",
      "            ReLU-443             [-1, 64, 7, 7]               0\n",
      "    conv_bn_relu-444             [-1, 64, 7, 7]               0\n",
      "          Conv2d-445             [-1, 16, 7, 7]           9,216\n",
      "     BatchNorm2d-446             [-1, 16, 7, 7]              32\n",
      "            ReLU-447             [-1, 16, 7, 7]               0\n",
      "    conv_bn_relu-448             [-1, 16, 7, 7]               0\n",
      "          Conv2d-449             [-1, 16, 7, 7]           2,304\n",
      "     BatchNorm2d-450             [-1, 16, 7, 7]              32\n",
      "            ReLU-451             [-1, 16, 7, 7]               0\n",
      "    conv_bn_relu-452             [-1, 16, 7, 7]               0\n",
      "     dense_layer-453            [-1, 672, 7, 7]               0\n",
      "          Conv2d-454             [-1, 64, 7, 7]          43,008\n",
      "     BatchNorm2d-455             [-1, 64, 7, 7]             128\n",
      "            ReLU-456             [-1, 64, 7, 7]               0\n",
      "    conv_bn_relu-457             [-1, 64, 7, 7]               0\n",
      "          Conv2d-458             [-1, 16, 7, 7]           9,216\n",
      "     BatchNorm2d-459             [-1, 16, 7, 7]              32\n",
      "            ReLU-460             [-1, 16, 7, 7]               0\n",
      "    conv_bn_relu-461             [-1, 16, 7, 7]               0\n",
      "          Conv2d-462             [-1, 64, 7, 7]          43,008\n",
      "     BatchNorm2d-463             [-1, 64, 7, 7]             128\n",
      "            ReLU-464             [-1, 64, 7, 7]               0\n",
      "    conv_bn_relu-465             [-1, 64, 7, 7]               0\n",
      "          Conv2d-466             [-1, 16, 7, 7]           9,216\n",
      "     BatchNorm2d-467             [-1, 16, 7, 7]              32\n",
      "            ReLU-468             [-1, 16, 7, 7]               0\n",
      "    conv_bn_relu-469             [-1, 16, 7, 7]               0\n",
      "          Conv2d-470             [-1, 16, 7, 7]           2,304\n",
      "     BatchNorm2d-471             [-1, 16, 7, 7]              32\n",
      "            ReLU-472             [-1, 16, 7, 7]               0\n",
      "    conv_bn_relu-473             [-1, 16, 7, 7]               0\n",
      "     dense_layer-474            [-1, 704, 7, 7]               0\n",
      "          Conv2d-475            [-1, 704, 7, 7]         495,616\n",
      "     BatchNorm2d-476            [-1, 704, 7, 7]           1,408\n",
      "            ReLU-477            [-1, 704, 7, 7]               0\n",
      "    conv_bn_relu-478            [-1, 704, 7, 7]               0\n",
      "          Linear-479                   [-1, 10]           7,050\n",
      "================================================================\n",
      "Total params: 2,247,210\n",
      "Trainable params: 2,247,210\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.57\n",
      "Forward/backward pass size (MB): 145.29\n",
      "Params size (MB): 8.57\n",
      "Estimated Total Size (MB): 154.44\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "torchsummary.summary(net, (3, 224, 224))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1955
    },
    "colab_type": "code",
    "id": "NbQebd0Ixmaf",
    "outputId": "f272377a-c530-4021-c683-3da80f3b0a77"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,    64/50000] loss: 0.0235753, lr: 0.1000000\n",
      "[1,  6464/50000] loss: 2.1234537, lr: 0.1000000\n",
      "[1, 12864/50000] loss: 1.9635283, lr: 0.1000000\n",
      "[1, 19264/50000] loss: 1.8610027, lr: 0.1000000\n",
      "[1, 25664/50000] loss: 1.8261792, lr: 0.1000000\n",
      "[1, 32064/50000] loss: 1.7400052, lr: 0.1000000\n",
      "[1, 38464/50000] loss: 1.7365363, lr: 0.1000000\n",
      "[1, 44864/50000] loss: 1.6703020, lr: 0.1000000\n",
      "[1 epoch] Accuracy of the network on the validation images: 45 %\n",
      "[2,    64/50000] loss: 0.0155567, lr: 0.0999753\n",
      "[2,  6464/50000] loss: 1.6658948, lr: 0.0999753\n",
      "[2, 12864/50000] loss: 1.6129764, lr: 0.0999753\n",
      "[2, 19264/50000] loss: 1.5673539, lr: 0.0999753\n",
      "[2, 25664/50000] loss: 1.5601296, lr: 0.0999753\n",
      "[2, 32064/50000] loss: 1.4787020, lr: 0.0999753\n",
      "[2, 38464/50000] loss: 1.4637226, lr: 0.0999753\n",
      "[2, 44864/50000] loss: 1.4298147, lr: 0.0999753\n",
      "[2 epoch] Accuracy of the network on the validation images: 55 %\n",
      "[3,    64/50000] loss: 0.0136490, lr: 0.0999013\n",
      "[3,  6464/50000] loss: 1.4258354, lr: 0.0999013\n",
      "[3, 12864/50000] loss: 1.3805990, lr: 0.0999013\n",
      "[3, 19264/50000] loss: 1.3457606, lr: 0.0999013\n",
      "[3, 25664/50000] loss: 1.3337588, lr: 0.0999013\n",
      "[3, 32064/50000] loss: 1.3066370, lr: 0.0999013\n",
      "[3, 38464/50000] loss: 1.2974196, lr: 0.0999013\n",
      "[3, 44864/50000] loss: 1.2882247, lr: 0.0999013\n",
      "[3 epoch] Accuracy of the network on the validation images: 61 %\n",
      "[4,    64/50000] loss: 0.0152328, lr: 0.0997781\n",
      "[4,  6464/50000] loss: 1.2650417, lr: 0.0997781\n",
      "[4, 12864/50000] loss: 1.2162155, lr: 0.0997781\n",
      "[4, 19264/50000] loss: 1.2262281, lr: 0.0997781\n",
      "[4, 25664/50000] loss: 1.2285759, lr: 0.0997781\n",
      "[4, 32064/50000] loss: 1.1962778, lr: 0.0997781\n",
      "[4, 38464/50000] loss: 1.2315221, lr: 0.0997781\n",
      "[4, 44864/50000] loss: 1.1439661, lr: 0.0997781\n",
      "[4 epoch] Accuracy of the network on the validation images: 64 %\n",
      "[5,    64/50000] loss: 0.0098561, lr: 0.0996057\n",
      "[5,  6464/50000] loss: 1.1536625, lr: 0.0996057\n",
      "[5, 12864/50000] loss: 1.1774682, lr: 0.0996057\n",
      "[5, 19264/50000] loss: 1.1535260, lr: 0.0996057\n",
      "[5, 25664/50000] loss: 1.1265387, lr: 0.0996057\n",
      "[5, 32064/50000] loss: 1.1023232, lr: 0.0996057\n",
      "[5, 38464/50000] loss: 1.1082277, lr: 0.0996057\n",
      "[5, 44864/50000] loss: 1.1154531, lr: 0.0996057\n",
      "[5 epoch] Accuracy of the network on the validation images: 67 %\n",
      "[6,    64/50000] loss: 0.0112841, lr: 0.0993844\n",
      "[6,  6464/50000] loss: 1.1110659, lr: 0.0993844\n",
      "[6, 12864/50000] loss: 1.0452108, lr: 0.0993844\n",
      "[6, 19264/50000] loss: 1.0842102, lr: 0.0993844\n",
      "[6, 25664/50000] loss: 1.0551710, lr: 0.0993844\n",
      "[6, 32064/50000] loss: 1.0576096, lr: 0.0993844\n",
      "[6, 38464/50000] loss: 1.0371934, lr: 0.0993844\n",
      "[6, 44864/50000] loss: 1.0210562, lr: 0.0993844\n",
      "[6 epoch] Accuracy of the network on the validation images: 71 %\n",
      "[7,    64/50000] loss: 0.0100457, lr: 0.0991144\n",
      "[7,  6464/50000] loss: 1.0099755, lr: 0.0991144\n",
      "[7, 12864/50000] loss: 1.0275308, lr: 0.0991144\n",
      "[7, 19264/50000] loss: 1.0061947, lr: 0.0991144\n",
      "[7, 25664/50000] loss: 0.9685200, lr: 0.0991144\n",
      "[7, 32064/50000] loss: 1.0099303, lr: 0.0991144\n",
      "[7, 38464/50000] loss: 1.0011832, lr: 0.0991144\n",
      "[7, 44864/50000] loss: 0.9545554, lr: 0.0991144\n",
      "[7 epoch] Accuracy of the network on the validation images: 71 %\n",
      "[8,    64/50000] loss: 0.0097056, lr: 0.0987958\n",
      "[8,  6464/50000] loss: 0.9688993, lr: 0.0987958\n",
      "[8, 12864/50000] loss: 0.9494280, lr: 0.0987958\n",
      "[8, 19264/50000] loss: 0.9734770, lr: 0.0987958\n",
      "[8, 25664/50000] loss: 0.9559171, lr: 0.0987958\n",
      "[8, 32064/50000] loss: 0.9655823, lr: 0.0987958\n",
      "[8, 38464/50000] loss: 0.9350255, lr: 0.0987958\n",
      "[8, 44864/50000] loss: 0.9407296, lr: 0.0987958\n",
      "[8 epoch] Accuracy of the network on the validation images: 74 %\n",
      "[9,    64/50000] loss: 0.0094797, lr: 0.0984292\n",
      "[9,  6464/50000] loss: 0.9201646, lr: 0.0984292\n",
      "[9, 12864/50000] loss: 0.9126517, lr: 0.0984292\n",
      "[9, 19264/50000] loss: 0.9193526, lr: 0.0984292\n",
      "[9, 25664/50000] loss: 0.9106997, lr: 0.0984292\n",
      "[9, 32064/50000] loss: 0.8985266, lr: 0.0984292\n",
      "[9, 38464/50000] loss: 0.8920104, lr: 0.0984292\n",
      "[9, 44864/50000] loss: 0.8955509, lr: 0.0984292\n",
      "[9 epoch] Accuracy of the network on the validation images: 75 %\n",
      "[10,    64/50000] loss: 0.0067820, lr: 0.0980147\n",
      "[10,  6464/50000] loss: 0.8711603, lr: 0.0980147\n",
      "[10, 12864/50000] loss: 0.8639726, lr: 0.0980147\n",
      "[10, 19264/50000] loss: 0.8580347, lr: 0.0980147\n",
      "[10, 25664/50000] loss: 0.8724021, lr: 0.0980147\n",
      "[10, 32064/50000] loss: 0.8489942, lr: 0.0980147\n",
      "[10, 38464/50000] loss: 0.8658338, lr: 0.0980147\n",
      "[10, 44864/50000] loss: 0.8796440, lr: 0.0980147\n",
      "[10 epoch] Accuracy of the network on the validation images: 77 %\n",
      "[11,    64/50000] loss: 0.0044342, lr: 0.0975528\n",
      "[11,  6464/50000] loss: 0.8451873, lr: 0.0975528\n",
      "[11, 12864/50000] loss: 0.8234024, lr: 0.0975528\n",
      "[11, 19264/50000] loss: 0.8229496, lr: 0.0975528\n",
      "[11, 25664/50000] loss: 0.8399056, lr: 0.0975528\n",
      "[11, 32064/50000] loss: 0.7883171, lr: 0.0975528\n",
      "[11, 38464/50000] loss: 0.8202239, lr: 0.0975528\n",
      "[11, 44864/50000] loss: 0.8219485, lr: 0.0975528\n",
      "[11 epoch] Accuracy of the network on the validation images: 78 %\n",
      "[12,    64/50000] loss: 0.0098846, lr: 0.0970440\n",
      "[12,  6464/50000] loss: 0.7971431, lr: 0.0970440\n",
      "[12, 12864/50000] loss: 0.7880013, lr: 0.0970440\n",
      "[12, 19264/50000] loss: 0.8241636, lr: 0.0970440\n",
      "[12, 25664/50000] loss: 0.8164813, lr: 0.0970440\n",
      "[12, 32064/50000] loss: 0.7776623, lr: 0.0970440\n",
      "[12, 38464/50000] loss: 0.7895857, lr: 0.0970440\n",
      "[12, 44864/50000] loss: 0.7877836, lr: 0.0970440\n",
      "[12 epoch] Accuracy of the network on the validation images: 78 %\n",
      "[13,    64/50000] loss: 0.0072434, lr: 0.0964888\n",
      "[13,  6464/50000] loss: 0.7637117, lr: 0.0964888\n",
      "[13, 12864/50000] loss: 0.7724887, lr: 0.0964888\n",
      "[13, 19264/50000] loss: 0.7642758, lr: 0.0964888\n",
      "[13, 25664/50000] loss: 0.7827165, lr: 0.0964888\n",
      "[13, 32064/50000] loss: 0.7677645, lr: 0.0964888\n"
     ]
    }
   ],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=initial_lr, momentum=0.9)\n",
    "learning_rate_scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=num_epoch)\n",
    "running_loss = 0.0\n",
    "\n",
    "  \n",
    "for epoch in range(num_epoch):  \n",
    "    learning_rate_scheduler.step()\n",
    "    for i, data in enumerate(train_loader, 0):\n",
    "        inputs, labels = data\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "                \n",
    "        show_period = 100\n",
    "        if i % show_period == 0:    # print every \"show_period\" mini-batches\n",
    "            print('[%d, %5d/50000] loss: %.7f, lr: %.7f' %\n",
    "                  (epoch + 1, (i + 1)*batch_size, running_loss / show_period, learning_rate_scheduler.get_lr()[0]))\n",
    "            running_loss = 0.0\n",
    "            \n",
    "    # validation part\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for i, data in enumerate(valid_loader, 0):\n",
    "        inputs, labels = data\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        outputs = net(inputs)\n",
    "        \n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        \n",
    "    print('[%d epoch] Accuracy of the network on the validation images: %d %%' % \n",
    "          (epoch + 1, 100 * correct / total)\n",
    "         )\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "y3pEm3QGFw7m"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "PeleeNet-PyTorch.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
